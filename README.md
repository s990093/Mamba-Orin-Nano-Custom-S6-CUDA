# ğŸš€ Mamba-Orin-Nano-Custom-S6-CUDA & Metal

## **è·¨å¹³å°æ¥µè‡´åŠ é€Ÿ Mamba SSMï¼šCUDA + TensorRT Plugin + Metal S6 Kernel**

![æ¶æ§‹åœ–](assets/architecture_diagram.png)

### **Jetson Orin Nano Ã— macOS M1/M2/M3 å…¨é¢æ”¯æ´**

å¾åµŒå…¥å¼é‚Šç·£æ¨ç†åˆ° Apple Silicon çš„ Metal GPUï¼Œæˆ‘å€‘æ‰“é€ ä¸€å¥— **è·¨ç¡¬é«”ã€è·¨å¾Œç«¯ã€å°ˆç‚º Mamba çµæ§‹åŒ–ç‹€æ…‹ç©ºé–“æ¨¡å‹ï¼ˆSSMï¼‰æ‰“é€ çš„æ¥µé€Ÿ S6 Kernel åŠ é€Ÿæ–¹æ¡ˆ**ã€‚

é€™æ˜¯ä¸€å€‹ **ã€Œä¸€æ¬¡å¯« Kernelï¼Œå…©é‚Šéƒ½è¶…å¿«ã€** çš„é‡å¿ƒå°ˆæ¡ˆã€‚
ç•¶ç„¶ï¼Œé‚„æœ‰ä¸€é»é»ã€Œå·¥ç¨‹å¸«éˆé­‚ä¸æ»…ã€çš„æµªæ¼«ã€‚

---

# ğŸŒŸ å°ˆæ¡ˆäº®é»ä¸€è¦½

## ğŸ”¥ Orin Nanoï¼šCUDA + TensorRT Plugin ç‰ˆæœ¬

ç‚º **Jetson Orin Nano (Ampere)** é‡èº«æ‰“é€ çš„ **S6 éæ­¸ Selective Scan åŠ é€Ÿå™¨**ï¼š

- **è‡ªå®šç¾© CUDA S6 Kernel**

  - Shared Memory + è¨˜æ†¶é«”è¨ªå•é‡æ’
  - Tiling ä»¥æ¶ˆé™¤é•·åºåˆ—éæ­¸ç“¶é ¸
  - Register reuse / é¿å… spilling
  - çµ‚æ¥µç›®æ¨™ï¼šè®“ DRAM ä¼‘æ¯ä¸€ä¸‹ï¼Œè®“ Compute è£å¿™ä¸€é»

- **TensorRT Plugin æ•´åˆ**

  - é¿å… Graph Break
  - èˆ‡ TensorRT-LLM GEMM èåˆ
  - æ”¯æ´ FP16 / INT8 / INT4 é‡åŒ–

- **é‚Šç·£è£ç½®æœ€ä½³åŒ–**

  - Zero-copyï¼ˆä½†è¦ç”¨å¾—å‰›å‰›å¥½ï¼Œä¸ç„¶æœƒè®Šåæ•ˆæœï¼‰
  - ç•°æ­¥ Stream pipeline
  - SWAP èˆ‡ NVMe èª¿æ•™

---

## ğŸ macOSï¼šMetal S6 Benchmarkï¼ˆM1/M2/M3ï¼‰

åŒä¸€å€‹ S6 éæ­¸é‚è¼¯ï¼Œé€™æ¬¡æ›æˆ **Metal Shading Language (MSL)**ï¼š

- å®Œæ•´å°æ‡‰ CUDA ç‰ˆçš„ S6 éæ­¸é‹ç®—
- ä½¿ç”¨ **Unified Memory** é¿å… CPU/GPU è¤‡è£½
- **FP16 half precision** åŠ é€Ÿ
- æ¯å€‹ Thread è™•ç†ä¸€å€‹ Channelï¼ˆå®Œå…¨ SIMD-friendlyï¼‰
- åšåˆ°ã€ŒApple Silicon ä¹Ÿè·‘å¾—é£›å¿«ã€çš„ç²¾ç¥ä½¿å‘½

ä½ å¯ä»¥æŠŠé€™æƒ³åƒæˆï¼š

> CUDA æ˜¯è‚Œè‚‰ç¡¬æ¼¢ç‰ˆï¼ŒMetal æ˜¯å„ªé›…å¿è€…ç‰ˆã€‚
> ç›®çš„åªæœ‰ä¸€å€‹ï¼šæŠŠéæ­¸ S6 æ‰“åˆ°å¿«åˆ°é£›èµ·ä¾†ã€‚

---

# ğŸ§± é‡æ–°æ•´ç†å¾Œçš„å°ˆæ¡ˆçµæ§‹ï¼ˆå« CUDA + Metalï¼‰

```
Mamba-Orin-Nano-Custom-S6-CUDA/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ custom_s6_kernel/           # CUDA Kernel (.cu / .cuh)
â”‚   â”œâ”€â”€ tensorrt_s6_plugin/         # TensorRT Plugin (.cpp / .hpp)
â”‚   â””â”€â”€ metal/                      # Metal S6 Kernel (.metal)
â”‚       â””â”€â”€ mamba_s6.metal
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ mamba_weights/              # æ¨¡å‹æ¬Šé‡
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ convert_model.py
â”‚   â”œâ”€â”€ build_tensorrt_engine.py
â”‚   â”œâ”€â”€ run_inference.py
â”‚   â””â”€â”€ mamba_metal_benchmark.py    # å°ˆçµ¦ macOS
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ design_report.md            # æŠ€è¡“å ±å‘Šï¼ˆæ”¾ä½ çš„è«–æ–‡ç´šåˆ†æï¼‰
â”‚
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ architecture_diagram.png
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

# âš™ï¸ å®‰è£èˆ‡ç’°å¢ƒè¨­å®š

---

# 1ï¸âƒ£ Jetson Orin Nanoï¼ˆCUDA + TensorRTï¼‰

### **éœ€æ±‚**

- JetPack (å« CUDA, cuDNN, TensorRT)
- Python 3.8+
- Build-essential / CMake

### **å®‰è£ä¾è³´**

```bash
sudo apt update
sudo apt install -y build-essential

python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### **ç·¨è­¯ S6 CUDA Kernel + TensorRT Plugin**

```bash
cd src/tensorrt_s6_plugin
mkdir build && cd build
cmake .. -DCUDA_ARCHITECTURES="8.7"
make -j$(nproc)

export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$(pwd)
```

---

# 2ï¸âƒ£ macOSï¼ˆMetal S6 Benchmarkï¼‰

### **éœ€æ±‚**

- macOS 12.0+
- M1 / M2 / M3ï¼ˆIntel Mac ç„¡æ³• GPU æ¸¬è©¦ï¼‰
- Python 3.x

### **å®‰è£ Metal Python binding**

```bash
pip3 install numpy pyobjc-framework-Metal pyobjc-framework-Cocoa
```

### **åŸ·è¡Œ Metal S6 benchmark**

```bash
python3 scripts/mamba_metal_benchmark.py
```

---

# ğŸš€ æ€§èƒ½é æœŸ

## Jetson Orin Nanoï¼ˆFP16 / INT8ï¼‰

| æ–¹æ³•                                         | é—œéµå„ªåŒ–                         | å»¶é² (ms/token) | ååé‡      |
| -------------------------------------------- | -------------------------------- | --------------- | ----------- |
| PyTorch baseline                             | S6 100% memory-bound             | >40             | <25         |
| TensorRT-LLM                                 | GEMM fused                       | 10â€“20           | 50â€“100      |
| **æœ¬å°ˆæ¡ˆï¼šS6 Custom CUDA Kernel + TensorRT** | **Shared Mem + Tiling + Plugin** | **5â€“10**        | **100â€“200** |
| **æœ¬å°ˆæ¡ˆï¼ˆINT8ï¼‰**                           | **é‡åŒ– + custom kernel**         | **< 5**         | **> 200**   |

## macOS Metalï¼ˆM1/M2/M3ï¼‰

- FP16 = å®Œå…¨ç”¨åŸç”Ÿ half precision
- Unified Memory = çœŸé›¶æ‹·è²
- Threadgroup = ä¸éœ€è¦å”ä½œä¹Ÿèƒ½å¤§æ®ºç‰¹æ®º

Metal ç‰ˆæœ¬å¯¦éš›ä¸Šæœƒå¾ˆæ¥è¿‘ CUDA FP16 ç‰ˆçš„ã€Œç†æƒ³ memory-bound ä¸Šé™ã€ï¼Œå¯ç”¨ä¾†é©—è­‰ï¼š

> **S6 éæ­¸æ¼”ç®—æ³•çš„ç¡¬é«”å¯æ”œæ€§**
> â†’ é€™ä»½æ¯”è¼ƒåœ¨ä½ çš„è«–æ–‡è£¡æœƒè¶…ç´šåŠ åˆ†ã€‚

---

# ğŸ§ª ä½¿ç”¨æ–¹æ³•

---

## 1ï¸âƒ£ æ¨¡å‹è½‰æ›ï¼ˆPyTorch â†’ ONNXï¼‰

```bash
python scripts/convert_model.py \
  --model_name "mamba-2.8b" \
  --output_path "models/mamba_onnx/mamba.onnx"
```

---

## 2ï¸âƒ£ å»ºæ§‹ TensorRT å¼•æ“ï¼ˆå« S6 Pluginï¼‰

```bash
python scripts/build_tensorrt_engine.py \
  --onnx_model_path "models/mamba_onnx/mamba.onnx" \
  --output_engine_path "models/mamba_tensorrt_engine.trt" \
  --s6_plugin_path "src/tensorrt_s6_plugin/build/libs6plugin.so" \
  --precision "fp16"
```

---

## 3ï¸âƒ£ åŸ·è¡Œæ¨ç†

```bash
python scripts/run_inference.py \
  --tensorrt_engine_path "models/mamba_tensorrt_engine.trt" \
  --input_text "The quick brown fox jumps over the lazy dog." \
  --sequence_length 1024 \
  --num_iterations 100 \
  --compare_pytorch
```

---

# ğŸ’¡ ç‚ºä»€éº¼è¦åŒæ™‚åš CUDA + Metalï¼Ÿ

å› ç‚ºé€™è®“ä½ å¯ä»¥ï¼š

- é©—è­‰ S6 éæ­¸æ ¸å¿ƒæ¼”ç®—æ³•çš„è·¨ç¡¬é«”ä¸€è‡´æ€§
- æ¸¬è©¦ memory-bound / compute-bound è¡Œç‚ºåœ¨å…©ç¨®æ¶æ§‹çš„å·®ç•°
- å¯¦ç¾ **portable backend**ï¼šã€ŒåŒä¸€å€‹æ¨¡å‹ï¼ŒåŒä¸€é‚è¼¯ï¼Œå“ªè£¡æœ‰ GPU æˆ‘å°±è·‘å“ªè£¡ã€

é€™å°æ–¼ä½ æœªä¾†æŠ•ç¨¿ã€è«–æ–‡ã€å±¥æ­·ã€é¢è©¦ï¼Œéƒ½æ˜¯éå¸¸ç‚«ç ²çš„äº®é»ã€‚

---

# ğŸ¤ è²¢ç»

æ­¡è¿æå‡ºï¼š

- Bug report
- Kernel å„ªåŒ–å»ºè­°
- Metal / CUDA / ROCm / Vulkan å…¶ä»–å¾Œç«¯ï¼ˆå°ï¼Œä½ å®Œå…¨å¯ä»¥æ“´å±•ï¼ï¼‰

---

# ğŸ“„ License

MIT License

---
